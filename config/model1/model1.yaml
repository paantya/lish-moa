# @package _group_
two_head: false
batch_size: 128
lr: auto
nfolds: 7
model:
  _target_: src.models.base.Model
  hidden_size: 1500
  dropout: 0.25
  two_head_factor: null
loss_tr:
  _target_: src.loss.loss.SmoothBCEwLogits
  smoothing: 0.001
loss_vl:
  _target_: torch.nn.BCEWithLogitsLoss
pl_modul:
  _target_: src.pl_module.LitMoANet
optimizer:
  name: adamw
  weight_decay: 0.001
dataloader:
  _target_: src.datamodule.single.MoADataModuleSingle
  batch_size: 128
dataset:
  _target_: src.datasets.single.MoADatasetSingle
pl_trainer:
  gpus: 0
  default_root_dir: '../models/'
  max_epochs: 100
  min_epochs: 10
  gradient_clip_val: 0.5